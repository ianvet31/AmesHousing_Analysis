---
title: "Data Analysis - Ames House Prices"
author: "Random85"
date: "2023-07-20"
output:
  pdf_document: default
  html_document: default
---

# The Dataset

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r, warning=FALSE}
library(faraway)
library(dplyr)
library(psych)
library(corrplot)
library(ggplot2)
library(ggcorrplot)
library(lares)
library(reshape2)
library(scales)

housing_data = read.csv("dataset\\AmesHousing.csv")

# summary(housing_data)

nrow(housing_data)
ncol(housing_data)

# Using small chunk of dataset for quick testing :)

#housing_data = housing_data[1:100,]

# Coercing categorical predictors into factor variables

housing_data[is.na(housing_data)] = 1

for (i in 1:ncol(housing_data)) {
  if (typeof(housing_data[, i]) == "character") {
    if (length(unique(housing_data[, i])) >= 2) {
      housing_data[, i] = as.factor(housing_data[, i])
    }
    
  }
}

housing_data$Yr.Sold = as.factor(housing_data$Yr.Sold)

str(housing_data)
```

First few examples:

```{r}
housing_data$SalePrice[1:10]
housing_data$Lot.Area[1:10]
housing_data$Utilities[1:10]
```


Dropping some of the columns that are not useful as a predictor for sale price.

```{r}
# Dropping the order and PID, looks like this is just for record keeping
housing_data = subset(housing_data, select = -c(Order, PID))

# Removing lot fraontage area, since we have lot area. Frontage is measurement of the house start to the street. It has way more null values
housing_data = subset(housing_data, select = -c(Lot.Frontage))

# Removing alley because we have street data
housing_data = subset(housing_data, select = -c(Alley))

# removing one condition column and exterior
housing_data = subset(housing_data, select = -c(Condition.2, Exterior.2nd))

```

### Location of the house could play a big role in house price, but for the dataset that is used, it has total 28 neighbors as follow:

```{r}
length(unique(housing_data[, "Neighborhood"]))
```

### We don't need this big list of dummy variable, so creating new variable as location based on some important factor

```{r}
# first converting the some exterior variables to numeric and then using it:
levels(housing_data[,"Exter.Cond"])
levels(housing_data[,"Exter.Qual"])
levels(housing_data[,"Functional"])

housing_data$Exter.Cond.Num = 5 - as.numeric(housing_data[, "Exter.Cond"])
housing_data$Exter.Qual.Num = 4 - as.numeric(housing_data[, "Exter.Qual"])
housing_data$Functional.Num = ifelse(housing_data[,"Functional"] == "Maj1", 8, 
                                     ifelse(housing_data[,"Functional"] == "Maj2", 7, 
                                            ifelse(housing_data[,"Functional"] == "Min1", 6,
                                                   ifelse(housing_data[,"Functional"] == "Min2", 5, 
                                                          ifelse(housing_data[,"Functional"] == "Mod", 4,
                                                                 ifelse(housing_data[,"Functional"] == "Typ", 3,
                                                                        ifelse(housing_data[,"Functional"] == "Sev", 2,
                                                                               ifelse(housing_data[,"Functional"] == "Sal", 1, 0))))))))

housing_data$Location = (housing_data[,"Overall.Qual"] / mean(housing_data[,"Overall.Qual"])) +
                        (housing_data[,"Overall.Cond"] / mean(housing_data[,"Overall.Cond"])) +
                        (housing_data[,"Exter.Cond.Num"] / mean(housing_data[,"Exter.Cond.Num"])) + 
                        (housing_data[,"Exter.Qual.Num"] / mean(housing_data[,"Exter.Qual.Num"])) +
                        (housing_data[,"Functional.Num"] / mean(housing_data[,"Functional.Num"]))

summary(housing_data[,"Location"])
```

### Converting ranked columns from factor to numeric

```{r}
#Function to convert Qual/Cond values into a numeric scale
convert_rank= function(col) {
col=replace(col,col=="Ex",values=5)
col=replace(col,col=="Gd",values=4 )
col=replace(col,col=="TA",values=3 )
col=replace(col,col=="Fa",values=2 )
col=replace(col,col=="Po",values=1 )
col=replace(col,col=="",values=0 )
as.numeric(col)
}
```
```{r}
#Create Numeric Columns for the rank
#Convert Bsmt Columns
#housing_data$Bsmt.Qual.Num=convert_rank(as.character(housing_data$Bsmt.Qual))
#housing_data$Bsmt.Cond.Num=convert_rank(as.character(housing_data$Bsmt.Cond))
#Convert Garage Columns
#housing_data$Garage.Cond.Num=convert_rank(as.character(housing_data$Garage.Cond))
#housing_data$Garage.Qual.Num=convert_rank(as.character(housing_data$Garage.Qual))
#Convert Exterior Columns
housing_data$Exter.Cond.Num=convert_rank(as.character(housing_data$Exter.Cond))
housing_data$Exter.Qual.Num=convert_rank(as.character(housing_data$Exter.Qual))
#Test equality after rank conversion
Ex=housing_data$Exter.Cond=="Gd"
test=housing_data$Exter.Cond.Num==4
#all.equal(Ex,test)
```



```{r}
#Now that data cleaning is done, we split Test and Train data
set.seed(720)
ames_trn_idx = sample(nrow(housing_data), size = trunc(0.80 * nrow(housing_data)))
ames_trn_data = housing_data[ames_trn_idx, ]
ames_tst_data = housing_data[-ames_trn_idx, ]
```

```{r, eval=FALSE}
View(housing_data)
```



# Collinearity and correlation analysis


```{r}

# Subsetting all the numeric elements of the dataset for collinearity and correlation analysis:

n_idxs = unlist(lapply(housing_data, is.numeric), use.names = FALSE)  
all_numeric_housing_data = housing_data[, n_idxs]
nhd = all_numeric_housing_data = housing_data[, n_idxs]
numeric_housing_data = subset(all_numeric_housing_data, select = -c(SalePrice))

#str(numeric_housing_data)



# MUST specify use = "complete.obs" argument to ignore NA's in dataset
corrs = round(cor(numeric_housing_data, use="complete.obs"), 2)


# some possible correlation plots?

#corrplot(corrs, method="number")
#ggcorrplot(corrs, lab_size = 0.1)

#corrs

ggplot(melt(corrs), aes(Var1, Var2, fill=value)) +
  geom_tile(height=0.9, width=0.9) +
  scale_fill_gradient2(low="blue", mid="white", high="red") +
  theme_minimal() +
  coord_equal() +
  labs(x="",y="",fill="Corr") +
  theme(axis.text.x=element_text(size=5, angle=45, vjust=1, hjust=1, 
                                 margin=margin(-3,0,0,0)),
        axis.text.y=element_text(size=5, margin=margin(0,-3,0,0)),
        panel.grid.major=element_blank()) 

```

Taking a closer look at some of the most correlated predictors:

```{r}

corr_cross(numeric_housing_data,
  max_pvalue = 0.05,
  top = 15 
)

# A few of these further visualized in pairs:
names(numeric_housing_data)

# pairs(numeric_housing_data, col = "dodgerblue")
```

While some of these high correlation measures are to be expected, such as house year built along garage year built, we can also see some non-trivial patterns start to emerge from the more continuous numeric predictors.


# Models (VP)

```{r}
#Functions to evaluate models
library(lmtest)

get_bp_decision = function(model, alpha) {
  decide = unname(bptest(model)$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_sw_decision = function(model, alpha) {
  decide = unname(shapiro.test(resid(model))$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_num_params = function(model) {
  length(coef(model))
}

get_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2,na.rm=TRUE))
}

get_adj_r2 = function(model) {
  summary(model)$adj.r.squared
}

compute_rmse = function(model) {
  sqrt(mean(resid(model)^2))
}

get_avg_per_error = function(model,newdata=ames_tst_data) {
  predicted = predict(model, newdata = newdata)
  n = nrow(newdata)
  error = abs(newdata$SalePrice - predicted)
  avg_per_error = ((1 / n) * (sum(error / predicted))) * 100
  avg_per_error
}

pred_graph= function(model,main="Predicted Vs. Actual") {
  predicted = predict(model, newdata = ames_tst_data)
  plot(
  ames_tst_data$SalePrice,
  predicted,
  ylab = "Predicted Price ($)",
  xlab = "Actual Price ($)",
  col = "blue",
  main = main
  )
  abline(a = 0, b = 1, lwd = 2)
}
```

### Make sure that location is corelated to saleprice and positive:

```{r}
cor(housing_data[,c("Location","SalePrice")])
```
### It has weak but a positive relation of with saleprice.

### Taking most relevant predictors that are logically be useful to build saleprice model with existing knowledge of real estate.
```{r}
# this model removes some of the qualities variable because it has some condition of those variables present
# Such as, keeping Bsmt.Cond and removing Bsmt.Qual (because both factor has almost same levels)

saleprice_full_model_selected = lm(SalePrice ~ MS.Zoning + Lot.Area + Street + Lot.Shape + Land.Contour + Utilities + Lot.Config + Land.Slope + Condition.1  + House.Style + Year.Built + Foundation + Location + Roof.Style + Exterior.1st + Total.Bsmt.SF + Bsmt.Cond + Bsmt.Full.Bath + Heating + Central.Air + Electrical + X1st.Flr.SF + X2nd.Flr.SF + Gr.Liv.Area + Full.Bath + Half.Bath + Bedroom.AbvGr + Kitchen.AbvGr + Kitchen.Qual + TotRms.AbvGrd + Fireplaces + Garage.Area + Paved.Drive + Wood.Deck.SF  + Open.Porch.SF + Pool.Area + Fence + Misc.Val + Mo.Sold + Yr.Sold, data = ames_trn_data)

saleprice_additive_model = lm(SalePrice ~ ., data = ames_trn_data)

saleprice_selected_backward_aic = step(saleprice_full_model_selected, direction = "backward", trace = 0)

```


```{r}
# check the number of predictors in the model
length(coef(saleprice_full_model_selected)) - 1
length(coef(saleprice_selected_backward_aic)) - 1
```
### Forward BIC Model - Full Additive Scope
```{r}
#Create BIC Forward model with Scope as full Additive
saleprice_additive_model = lm(SalePrice ~ ., data = ames_trn_data)
form_add=update(formula(saleprice_additive_model),.~.-Misc.Feature)
start=lm(SalePrice ~ 1,data=ames_trn_data)
n=nrow(ames_trn_data)
bic_for_mod=step(start,direction = "forward",scope = form_add ,k=log(n),trace=0)
```

### Taking most relevant predictors that are logically be useful to build saleprice model with existing knowledge of real estate.
```{r}
# this model removes some of the qualities variable because it has some condition of those variables present
# Such as, keeping Bsmt.Cond and removing Bsmt.Qual (because both factor has almost same levels)
saleprice_full_model_selected = lm(SalePrice ~ MS.Zoning + Lot.Area + Street + Lot.Shape + Land.Contour + Utilities + Lot.Config + Land.Slope + Condition.1  + House.Style + Year.Built + Foundation + Location + Roof.Style + Exterior.1st + Total.Bsmt.SF + Bsmt.Cond + Bsmt.Full.Bath + Heating + Central.Air + Electrical + X1st.Flr.SF + X2nd.Flr.SF + Gr.Liv.Area + Full.Bath + Half.Bath + Bedroom.AbvGr + Kitchen.AbvGr + Kitchen.Qual + TotRms.AbvGrd + Fireplaces + Garage.Area + Paved.Drive + Wood.Deck.SF  + Open.Porch.SF + Pool.Area + Fence + Misc.Val + Mo.Sold + Yr.Sold, data = ames_trn_data)
saleprice_selected_backward_aic = step(saleprice_full_model_selected, direction = "backward", trace = 0)
```
```{r}
# check the number of predictors in the model
length(coef(saleprice_full_model_selected)) - 1
length(coef(saleprice_selected_backward_aic)) - 1
```

### Testing the built model
```{r}
get_loocv_rmse(saleprice_additive_model)
get_loocv_rmse(saleprice_full_model_selected)
get_loocv_rmse(saleprice_selected_backward_aic)
```
### Even though removing so many variables, the model is still very huge, so, removing some of the variables that are may be corelated. Also, removing the variables that seems related based on the common real estate knowledge.


```{r}

saleprice_full_model_selected_reduced = lm(SalePrice ~ MS.Zoning + Lot.Area + Street + Lot.Shape + Utilities + Land.Slope + House.Style + Year.Built + Foundation + Location + Heating + Central.Air + Electrical + Gr.Liv.Area + Full.Bath + Bedroom.AbvGr + Kitchen.AbvGr + Kitchen.Qual + TotRms.AbvGrd + Fireplaces + Garage.Area + Paved.Drive + Wood.Deck.SF  + Open.Porch.SF + Pool.Area + Fence + Misc.Val + Yr.Sold  , data = ames_trn_data)

saleprice_selected_reduced_backward_aic = step(saleprice_full_model_selected_reduced, direction = "backward", trace = 0)

summary(saleprice_selected_reduced_backward_aic)
```

```{r}
# temp
length(coef(saleprice_full_model_selected_reduced)) - 1
length(coef(saleprice_selected_reduced_backward_aic)) - 1
```

### Testing the built model
```{r}
get_loocv_rmse(saleprice_additive_model)
get_loocv_rmse(saleprice_full_model_selected_reduced)
get_loocv_rmse(saleprice_selected_reduced_backward_aic)
```

```{r}
anova(saleprice_full_model_selected_reduced, saleprice_selected_reduced_backward_aic)
```

# Variable transformations

For this section, we'll begin by visualizing the relationships between the house sale prices and some of our predictors. By doing this, we're looking to gain some insight into potential variable transformations we could implement in order to improve the performance of our models. 

```{r}
par(mfrow = c(2, 2))    

plot(SalePrice ~ Lot.Area, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Lot area")

plot(SalePrice ~ X1st.Flr.SF, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs First floor area")

plot(SalePrice ~ X2nd.Flr.SF, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Second floor area")

plot(SalePrice ~ Garage.Area, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Garage area")
```

```{r}

par(mfrow = c(2, 2))    

plot(SalePrice ~ Total.Bsmt.SF, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Basement area")

plot(SalePrice ~ Overall.Qual, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Overall quality")

plot(SalePrice ~ Year.Built, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Year built")

plot(SalePrice ~ Overall.Cond, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Overall condition")
```

```{r}

par(mfrow = c(2, 2))   

plot(SalePrice ~ Gr.Liv.Area, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Living area")

plot(SalePrice ~ Full.Bath, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs # of full bathrooms")

plot(SalePrice ~ MS.SubClass, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs MS Subclass")

plot(SalePrice ~ Wood.Deck.SF, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Deck area")
```

```{r}

par(mfrow = c(2, 2))    

plot(SalePrice ~ Bsmt.Unf.SF, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Basement unfinished area")

plot(SalePrice ~ BsmtFin.SF.1, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Basement finished area")

plot(SalePrice ~ Mo.Sold, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Month sold")

plot(SalePrice ~ TotRms.AbvGrd, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Total rooms above ground")
```

```{r}
plot(SalePrice ~ Neighborhood, data = housing_data, col = "grey", pch = 20, cex = 0.3,
     main = "Sale price vs Neighborhood")
```


```{r}

transformed_model_old = lm(SalePrice ~ MS.Zoning + log(Lot.Area) + Street + Lot.Shape + Land.Slope + House.Style + I(Year.Built^2) + Foundation + Location + Central.Air + Gr.Liv.Area + Bedroom.AbvGr + Kitchen.AbvGr + Kitchen.Qual + TotRms.AbvGrd + (Fireplaces) + I(Garage.Area^2) + (Wood.Deck.SF) + I(Pool.Area^2) + sqrt(Misc.Val) + Exter.Qual + log(TotRms.AbvGrd) + I(BsmtFin.SF.1^3) + Overall.Qual, data = ames_trn_data)


transformed_model = lm(SalePrice ~ MS.Zoning + log(Lot.Area) + Street + I(Year.Built^2) + Kitchen.AbvGr + Bedroom.AbvGr + Gr.Liv.Area + log(TotRms.AbvGrd) + (Fireplaces) + I(Garage.Area^2) + Wood.Deck.SF + I(Pool.Area^2) + I(BsmtFin.SF.1^3) + sqrt(Misc.Val) + I(Overall.Qual^5) + I(Gr.Liv.Area^2) + House.Style + Lot.Shape + Land.Slope + Foundation + Exter.Qual + Exter.Cond, data = ames_trn_data)

get_loocv_rmse(saleprice_selected_reduced_backward_aic)
get_loocv_rmse(transformed_model_old)
get_loocv_rmse(transformed_model)

sqrt(mean((ames_trn_data$SalePrice - fitted(saleprice_selected_reduced_backward_aic)) ^ 2))
sqrt(mean((ames_trn_data$SalePrice - fitted(transformed_model_old)) ^ 2))
sqrt(mean((ames_trn_data$SalePrice - fitted(transformed_model)) ^ 2))

```

```{r}
par(mfrow = c(2,2))

plot(fitted(saleprice_selected_reduced_backward_aic), resid(saleprice_selected_reduced_backward_aic), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted v Residuals BIC")
abline(h = 0, col = "darkorange", lwd = 2)

qqnorm(resid(saleprice_selected_reduced_backward_aic), main = "Q-Q Plot BIC", col = "darkgrey")
qqline(resid(saleprice_selected_reduced_backward_aic), col = "dodgerblue", lwd = 2)

plot(fitted(transformed_model), resid(transformed_model), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted v Residuals transform")
abline(h = 0, col = "darkorange", lwd = 2)

qqnorm(resid(transformed_model), main = "Q-Q Plot transform", col = "darkgrey")
qqline(resid(transformed_model), col = "dodgerblue", lwd = 2)

```

After adding some polynomial and logarithmic kernel transformations to applicable predictor variables, we can see some noticeable improvement in both RMSE and LOOCV-RMSE metrics when comparing to the reduced backward-BIC model from earlier.

```{r}
formula(bic_for_mod)
```
```{r}
transformed_bic_mod=lm(SalePrice ~ Overall.Qual + Gr.Liv.Area + Neighborhood + Bsmt.Qual + 
    BsmtFin.SF.1 + Roof.Matl + MS.SubClass + Bsmt.Exposure + 
    Kitchen.Qual + Overall.Cond + I(Garage.Area^2) + sqrt(Misc.Val) + I(Year.Built^2) + 
    Exter.Qual + log(Lot.Area) + Screen.Porch + (Fireplaces) + Sale.Condition + 
    Functional.Num + Bsmt.Full.Bath + Total.Bsmt.SF + Bldg.Type + 
    Full.Bath + Mas.Vnr.Area + X2nd.Flr.SF,data=ames_trn_data)
```
# Model Evaluations
```{r}
library(knitr)
models=list(transformed_model,saleprice_full_model_selected,saleprice_full_model_selected_reduced,saleprice_selected_backward_aic,saleprice_selected_reduced_backward_aic,bic_for_mod,transformed_bic_mod)

RMSE =lapply(lapply(models, compute_rmse), round, 2)
LOOCV_RMSE= lapply(lapply(models,get_loocv_rmse), round, 2)
AVG_ERROR= lapply(lapply(models,get_avg_per_error), round, 2)
ADJ_R2= lapply(lapply(models,get_adj_r2), round, 2)
BP_TEST= lapply(models,get_bp_decision,alpha=.90)
SW_TEST= lapply(models,get_sw_decision,alpha=.90)

Models=c("transformed_model","saleprice_full_model_selected","saleprice_full_model_selected_reduced","saleprice_selected_backward_aic","saleprice_selected_reduced_backward_aic","bic_for_mod","transformed_bic_mod")
evaluation=cbind(Models,RMSE,LOOCV_RMSE,AVG_ERROR,ADJ_R2,BP_TEST,SW_TEST)
kable(evaluation)


hist(resid(transformed_model),
     xlab   = "Residuals",
     main   = "transformed_model",
     col    = "darkorange",
     border = "dodgerblue",
     breaks = 100)


shapiro.test(resid(transformed_model))
ks.test(resid(transformed_model), "pnorm")


shapiro.test(rnorm(499, mean=0, sd=1000))

```

```{r}

par(mfrow = c(1,2))
pred_graph(transformed_model,main="Transformed")
pred_graph(transformed_bic_mod,main="Transformed BIC")
```
